# Title
## Intro
## Background on methods
### Reinforcment learning
    It is common practice to use certain language when describing what RL is in machine learning. We must understand what state, reward, environment, policy, and action are in regards to RL. State refers to the progress and data that has been collected at a given point in a learning process. Each step, or iteration bring the program to the next state. The environment is the way that a programmer initializes the problem at hand in the code. There are many different types of machine learning environments. A policy refers to the way that the program applies a reward. The reward is essential how we keep track of the action taken by the program, and if it was productive in the learning process.
    In other words, RL is a style of machine learning that requires a reward. We use the reward in RL by assigning a policy that applies to a given environment. An environment is an instance of the problem, or obstacles that you want your program to gain insight on. When the program makes an action oppon a state and that action makes progress towards the end goal, then the reward policy will provide reward. The program will then reference this data for the next step in order to achieve the end goal.
### Meta-RL
### Quantum Computing
## Our Method
### Meta-RL + QNN
## The problem / testing our method
### Stock market problem
### Compare Performance from other methods
## Conclusion
## Bibliography